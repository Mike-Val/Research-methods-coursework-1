{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'csv/ScienceDirect.csv': ('Url', 'Title'),\n",
    "    'csv/ieee.csv': ('PDF Link', 'Document Title'),\n",
    "    'csv/acm.csv': ('Url', 'Title'),\n",
    "    'csv/springer.csv': ('URL', 'Item Title'),\n",
    "}\n",
    "\n",
    "files = {Path(k): v for k, v in files.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total papers: 344 in 4 sources:\n",
      "\tScienceDirect.csv -> 12\n",
      "\tieee.csv -> 112\n",
      "\tacm.csv -> 41\n",
      "\tspringer.csv -> 179\n"
     ]
    }
   ],
   "source": [
    "data = {k: pd.read_csv(k) for k in files.keys()}\n",
    "\n",
    "print(f'Total papers: {sum(len(d) for d in data.values())} in {len(data)} sources:')\n",
    "for f, d in data.items():\n",
    "    print(f'\\t{f.name} -> {len(d)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicates: 8\n",
      "\tacm.csv and ieee.csv -> Binary Code Clone Detection across Architectures and Compiling Configurations\n",
      "\tacm.csv and ieee.csv -> Transferring Code-Clone Detection and Analysis to Practice\n",
      "\tacm.csv and ieee.csv -> A Novel Neural Source Code Representation Based on Abstract Syntax Tree\n",
      "\tacm.csv and ieee.csv -> SCDetector: Software Functional Clone Detection Based on Semantic Tokens Analysis\n",
      "\tacm.csv and ieee.csv -> MoCoP: Towards a Model Clone Portal\n",
      "\tacm.csv and ieee.csv -> PHANTA: Diversified Test Code Quality Measurement for Modern Software Development\n",
      "\tacm.csv and ieee.csv -> A Mocktail of Source Code Representations\n",
      "\tacm.csv and ieee.csv -> Unleashing the Power of Compiler Intermediate Representation to Enhance Neural Program Embeddings\n"
     ]
    }
   ],
   "source": [
    "duplicates = {}\n",
    "\n",
    "for f in files.keys():\n",
    "    for idx, row in data[f].iterrows():\n",
    "        title = row[files[f][1]].strip()\n",
    "        for k in data.keys():\n",
    "            if k != f and title in [t.strip() for t in data[k][files[k][1]].values]:\n",
    "                duplicates[title] = (f, k)\n",
    "\n",
    "print(f'Total duplicates: {len(duplicates)}')\n",
    "for k, v in duplicates.items():\n",
    "    print(f'\\t{v[0].name} and {v[1].name} -> {k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "from dotmap import DotMap\n",
    "\n",
    "browser = webbrowser.get('firefox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files already seen: 298 in 4 sources:\n"
     ]
    }
   ],
   "source": [
    "relevant = {}\n",
    "discard = {}\n",
    "review = {}\n",
    "\n",
    "for f, d in data.items():\n",
    "    try:\n",
    "        relevant[f] = pd.read_csv(Path(f'./relevant/{f.name}'))\n",
    "        discard[f] = pd.read_csv(Path(f'./discard/{f.name}'))\n",
    "        review[f] = pd.read_csv(Path(f'./review/{f.name}'))\n",
    "    except FileNotFoundError:\n",
    "        relevant[f] = pd.DataFrame(columns=d.columns)\n",
    "        discard[f] = pd.DataFrame(columns=d.columns)\n",
    "        review[f] = pd.DataFrame(columns=d.columns)\n",
    "\n",
    "total = 0\n",
    "for s in [relevant, discard, review]:\n",
    "    for f, d in s.items():\n",
    "        total += len(d)\n",
    "print(f'Total files already seen: {total} in {len(relevant)} sources:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5055590187c49098a8af15cd11ec8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sources:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering csv/ScienceDirect.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be4563412d047ffb858d89aeefec445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Papers:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ScienceDirect.csv\n",
      "Filtering csv/ieee.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54fdefbf76bd47a189f4027d4f95807e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Papers:   0%|          | 0/112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ieee.csv\n",
      "Filtering csv/acm.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6c977f6069405d8e3e026e11c7b735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Papers:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving acm.csv\n",
      "Filtering csv/springer.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6068276e983476d8ce016754aad8c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Papers:   0%|          | 0/179 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid input\n",
      "Saving springer.csv\n"
     ]
    }
   ],
   "source": [
    "for f, d in tqdm(data.items(), desc='Sources', total=len(data)):\n",
    "    tqdm.write(f'Filtering {f}')\n",
    "    quit = False\n",
    "    \n",
    "    for idx, row in tqdm(d.iterrows(), desc='Papers', leave=False, total=len(d)):\n",
    "        url = row[files[f][0]]\n",
    "\n",
    "        if url in relevant[f][files[f][0]].values or url in discard[f][files[f][0]].values or url in review[f][files[f][0]].values:\n",
    "            continue\n",
    "\n",
    "        browser.open(url)\n",
    "\n",
    "        while (check := input(f'Keep {url}? [y/n] ')) not in ['y', 'n', 'q', 'r']:\n",
    "            print('Invalid input')\n",
    "        if check == 'y':\n",
    "            relevant[f] = pd.concat([relevant[f], row.to_frame().T], ignore_index=True)\n",
    "        elif check == 'n':\n",
    "            discard[f] = pd.concat([discard[f], row.to_frame().T], ignore_index=True)\n",
    "        elif check == 'r':\n",
    "            review[f] = pd.concat([review[f], row.to_frame().T], ignore_index=True)\n",
    "        elif check == 'q':\n",
    "            quit = True\n",
    "            break\n",
    "    tqdm.write(f'Saving {f.name}')\n",
    "    relevant[f].to_csv(Path(f'./relevant/{f.name}'), index=False)\n",
    "    discard[f].to_csv(Path(f'./discard/{f.name}'), index=False)\n",
    "    review[f].to_csv(Path(f'./review/{f.name}'), index=False)\n",
    "    if quit:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis results:\n",
      "\tScienceDirect.csv -> 9 relevant, 3 discarded, 0 to review\n",
      "\tieee.csv -> 81 relevant, 31 discarded, 0 to review\n",
      "\tacm.csv -> 21 relevant, 20 discarded, 0 to review\n",
      "\tspringer.csv -> 39 relevant, 140 discarded, 0 to review\n"
     ]
    }
   ],
   "source": [
    "print(f'Analysis results:')\n",
    "for f in files.keys():\n",
    "    print(f'\\t{f.name} -> {len(relevant[f])} relevant, {len(discard[f])} discarded, {len(review[f])} to review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56c834e9f2f29bf928851a9e21c258c5f911f60c6786dcefca87fe83f9ef38b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
